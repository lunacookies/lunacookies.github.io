<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Part Eighteen: Errors · arzg’s website</title><link rel=stylesheet href=https://arzg.github.io/scss/main.04c23afe51262a10ee61829da41f4d7318ff311ed0d0bcbf1db0fde96e3830f4.css integrity="sha256-BMI6/lEmKhDuYYKdpB9Ncxj/MR7Q0Ly/HbD96W44MPQ="><script src=https://unpkg.com/quicklink@2.0.0/dist/quicklink.umd.js></script>
<script src=https://unpkg.com/anchor-js@4.3.1/anchor.min.js></script>
<script src=https://unpkg.com/prismjs@1.25.0/components/prism-core.min.js></script>
<script src=https://unpkg.com/prismjs@1.25.0/plugins/autoloader/prism-autoloader.min.js></script>
<script>window.onload=()=>{quicklink.listen()},document.addEventListener("DOMContentLoaded",function(a){anchors.add("main h1")})</script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest></head><body><nav class=site-navigation><ul><li><a href=/>Home</a></li><li><a href=/blog/>Blog</a></li><li class=current><a href=/lang/>Make A Language</a></li></ul></nav><header class=header-area><h1 class=title>Part Eighteen: Errors</h1><section class=page-info><ul><li>21 December 2020</li><li>6301 words</li><li>32 minute read</li></ul></section></header><main><p>So far, our parser has only concerned itself with input that is correct. In a world of IDEs and language servers, however, the input to our parser will be wrong more often than not. Therefore, it is important that our parser can:</p><ul><li>recover gracefully from errors</li><li>infer as detailed a syntax tree from the input as possible</li><li>report errors in a user-friendly manner</li></ul><p>Unfortunately for us, the only thing our parser currently supports is arithmetic expressions, which don’t make error recovery techniques easy to demonstrate. Let’s first implement a parser for variable definitions.</p><h1 id=variable-definitions>Variable definitions</h1><p>Since variable definitions aren’t expressions, we shouldn’t put them in the <code>expr</code> module. Let’s create a new <code>stmt</code> module for statements:</p><pre><code class=language-rust>// grammar.rs

mod expr;
mod stmt;
</code></pre><pre><code class=language-rust>// crates/parser/src/grammar/stmt.rs

use super::*;

pub(super) fn stmt(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    todo!()
}
</code></pre><p>We’ll use the same syntax for variable definitions as we used before the rewrite:</p><pre><code>let name = expr
</code></pre><p>A test:</p><pre><code class=language-rust>#[cfg(test)]
mod tests {
    use crate::check;
    use expect_test::expect;

    #[test]
    fn parse_variable_definition() {
        check(
            &quot;let foo = bar&quot;,
            expect![[r#&quot;
Root@0..13
  VariableDef@0..13
    LetKw@0..3 &quot;let&quot;
    Whitespace@3..4 &quot; &quot;
    Ident@4..7 &quot;foo&quot;
    Whitespace@7..8 &quot; &quot;
    Equals@8..9 &quot;=&quot;
    Whitespace@9..10 &quot; &quot;
    VariableRef@10..13
      Ident@10..13 &quot;bar&quot;&quot;#]],
        );
    }
}
</code></pre><p>We can now implement parsing of variable definitions:</p><pre><code class=language-rust>pub(super) fn stmt(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    match p.peek() {
        Some(SyntaxKind::LetKw) =&gt; variable_def(p),
        _ =&gt; None,
    }
}

fn variable_def(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    assert!(p.at(SyntaxKind::LetKw));
    let m = p.start();
    p.bump();

    assert!(p.at(SyntaxKind::Ident));
    p.bump();

    assert!(p.at(SyntaxKind::Equals));
    p.bump();

    expr::expr(p)?;

    Some(m.complete(p, SyntaxKind::VariableDef))
}
</code></pre><p>Instead of handling errors, we repeatedly <code>assert</code> the token we’re at; since we know at that point the token we’re at, we can just <code>bump</code> past it.</p><p>Let’s quickly define <code>SyntaxKind::VariableDef</code>:</p><pre><code class=language-rust>// crates/syntax/src/lib.rs

#[derive(Debug, Copy, Clone, PartialEq, FromPrimitive, ToPrimitive)]
pub enum SyntaxKind {
    // snip
    Root,
    InfixExpr,
    Literal,
    ParenExpr,
    PrefixExpr,
    VariableDef,
    VariableRef,
}
</code></pre><p>Our parser compiles, but we get a failing test because <code>root</code> doesn’t use <code>stmt</code>. The solution is to have <code>stmt</code> fall back to calling <code>expr</code> if it isn’t sure what it’s looking at:</p><pre><code class=language-rust>// crates/parser/src/grammar/stmt.rs

pub(super) fn stmt(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    match p.peek() {
        Some(SyntaxKind::LetKw) =&gt; variable_def(p),
        _ =&gt; expr::expr(p),
    }
}
</code></pre><p>We can now call <code>stmt</code> from <code>root</code>:</p><pre><code class=language-rust>// grammar.rs

pub(crate) fn root(p: &amp;mut Parser) -&gt; CompletedMarker {
    let m = p.start();
    stmt::stmt(p);

    m.complete(p, SyntaxKind::Root)
}
</code></pre><pre><code class=language-->$ cargo t -q --lib

running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out


running 18 tests
...............F..
failures:

---- grammar::stmt::tests::parse_variable_definition stdout ----
thread 'grammar::stmt::tests::parse_variable_definition' panicked at 'Markers need to be completed', /home/me/.cargo/registry/src/github.com-1ecc6299db9ec823/drop_bomb-0.1.5/src/lib.rs:113:13
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace


failures:
    grammar::stmt::tests::parse_variable_definition

test result: FAILED. 17 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>What seems to have happened is that <code>expr</code> has returned <code>None</code>, causing <code>variable_def</code> to return early, which in turn means the marker isn’t completed. Since we don’t care about error handling yet, we can add an <code>unwrap</code>:</p><pre><code class=language-rust>// stmt.rs

pub(super) fn stmt(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    match p.peek() {
        Some(SyntaxKind::LetKw) =&gt; Some(variable_def(p)),
        _ =&gt; expr::expr(p),
    }
}

fn variable_def(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert!(p.at(SyntaxKind::LetKw));
    let m = p.start();
    p.bump();

    assert!(p.at(SyntaxKind::Ident));
    p.bump();

    assert!(p.at(SyntaxKind::Equals));
    p.bump();

    expr::expr(p).unwrap();

    m.complete(p, SyntaxKind::VariableDef)
}
</code></pre><pre><code class=language-->$ cargo t -q --lib

running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out


running 18 tests
..............F...
failures:

---- grammar::stmt::tests::parse_variable_definition stdout ----
thread 'grammar::stmt::tests::parse_variable_definition' panicked at 'called `Option::unwrap()` on a `None` value', crates/parser/src/grammar/stmt.rs:21:19
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace


failures:
    grammar::stmt::tests::parse_variable_definition

test result: FAILED. 17 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>Huh, that’s weird; why is <code>expr</code> returning <code>None</code>? The only places where it can do so are <code>let lhs = lhs()?;</code> and if it doesn’t see an operator. Oh, <em>wait.</em></p><p>We should be returning <code>lhs</code> at that point instead:</p><pre><code class=language-rust>fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) -&gt; Option&lt;CompletedMarker&gt; {
    let mut lhs = lhs(p)?; // we’ll handle errors later.

    loop {
        let op = match p.peek() {
            // snip
            _ =&gt; break, // we’ll handle errors later.
        };

        // snip
    }

    Some(lhs)
}
</code></pre><pre><code class=language-->$ cargo t -q --lib

running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out


running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><h1 id=a-short-intermission>A short intermission</h1><p>Let’s say the parser is being used as part of a language server, and the user has typed out a variable definition:</p><pre><code>let b = a
</code></pre><p>They realise they haven’t defined <code>a</code>, so they define it above:</p><pre><code>let a = 10
let b = a
</code></pre><p>While the user is in the middle of typing that, our parser sees this:</p><pre><code>let a =
let b = a
</code></pre><p>What we want is for our parser to recognise two variable definitions, with the first missing an expression. This way, language intelligence like Go To Definition can continue working in spite of an incomplete file; if we tell the editor to ‘go to the definition of <code>a</code>’, it will know where to go because it’s recognised two separate variable definitions. The parser would also report an error on the second <code>let</code> keyword along the lines of</p><pre><code>expected number, identifier, ‘-’ or ‘(’, but found ‘let’
</code></pre><p>Our goal for the rest of this part is to make Eldiro have this behaviour.</p><h1 id=a-naive-strategy-for-error-recovery>A naive strategy for error recovery</h1><p>This is the simplest of all the error recovery techniques; if you expect to see a <code>Foo</code>, but see something else, you skip tokens until you find a <code>Foo</code>. This is simple to implement but doesn’t deliver the best output, since it throws away a lot of possibly-useful tokens. For example, all the underlined tokens here are thrown away:</p><pre><code class=language-->let a =
let b = a
-------
</code></pre><p>Here the IDE’s Go To Definition on <code>a</code> wouldn’t work, and the user would get an ‘undefined variable <code>a</code>’ error. Evidently, this error recovery strategy doesn’t let us achieve the ideal case we laid out before.</p><h1 id=a-better-way>A better way</h1><p>The idea is to start with the above approach, but <em>don’t skip certain tokens.</em> For example, let’s say we have the following code:</p><pre><code>{
  let a = {
    let bar =
  }
  10
}
</code></pre><p>The naive approach would start looking for an expression after the <code>let bar =</code>, and would stop throwing away tokens at <code>10</code>. It now consumes the final <code>}</code> to close the <code>let a = {</code> block. This doesn’t leave a <code>}</code> to close the surrounding block, though, which means the user gets an ‘unclosed <code>{</code>’ error. Here’s roughly what the parser sees if you don’t include errors and fix the indentation:</p><pre><code>{
  let a = {
    let bar = 10
  }
</code></pre><p>With the fancier approach, we can tell the parser not to skip <code>}</code> tokens, since those are important for recognising program structure. In languages with explicit statement terminators, parsers are often constructed so that <code>;</code> is never skipped. These tokens that aren’t to be skipped by the parser during error recovery are called ‘recovery sets’.</p><p>We can improve on this approach by only ever skipping one token, which means we throw away even less of the input.</p><p>Remember that ideal example from earlier?</p><pre><code>let a =
let b = a
</code></pre><p>We can achieve the goal of recognising two variable declarations by including <code>let</code> in the parser’s recovery set. This way, whenever the parser encounters an unexpected <code>let</code>, it will stop parsing what it’s up to and keep returning from subparsers until it gets to a state in which <code>let</code> can be recognised.</p><h1 id=implementing-error-recovery>Implementing error recovery</h1><p>Let’s write a test for the case we just discussed:</p><pre><code class=language-rust>// stmt.rs

#[cfg(test)]
mod tests {
    // snip

    #[test]
    fn recover_on_let_token() {
        check(
            &quot;let a =\nlet b = a&quot;,
            expect![[r#&quot;
Root@0..17
  VariableDef@0..8
    LetKw@0..3 &quot;let&quot;
    Whitespace@3..4 &quot; &quot;
    Ident@4..5 &quot;a&quot;
    Whitespace@5..6 &quot; &quot;
    Equals@6..7 &quot;=&quot;
    Whitespace@7..8 &quot;\n&quot;
  VariableDef@8..17
    LetKw@8..11 &quot;let&quot;
    Whitespace@11..12 &quot; &quot;
    Ident@12..13 &quot;b&quot;
    Whitespace@13..14 &quot; &quot;
    Equals@14..15 &quot;=&quot;
    Whitespace@15..16 &quot; &quot;
    VariableRef@16..17
      Ident@16..17 &quot;a&quot;&quot;#]],
        );
    }
}
</code></pre><p>Let’s write an <code>expect</code> method on <code>Parser</code> that takes a given <code>SyntaxKind</code> and <code>bump</code>s past it if the parser is up to it; if it isn’t, then we might skip the token depending on whether it’s part of the recovery set:</p><pre><code class=language-rust>// parser.rs

const RECOVERY_SET: [SyntaxKind; 1] = [SyntaxKind::LetKw];

// snip

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn expect(&amp;mut self, kind: SyntaxKind) {
        if self.at(kind) || !self.peek().map_or(false, |k| RECOVERY_SET.contains(&amp;k)) {
            self.bump();
        }
    }

    // snip
}
</code></pre><p>Let’s use this method in <code>variable_def</code>:</p><pre><code class=language-rust>// stmt.rs

fn variable_def(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert!(p.at(SyntaxKind::LetKw));
    let m = p.start();
    p.bump();

    p.expect(SyntaxKind::Ident);
    p.expect(SyntaxKind::Equals);

    expr::expr(p).unwrap();

    m.complete(p, SyntaxKind::VariableDef)
}
</code></pre><p>Although this <em>does</em> make the code cleaner, the test still fails. After all, the part that’s breaking it is in <code>expr</code>, not here!</p><p>Let’s write an <code>error</code> method that we can call if <code>expr</code> has exhausted all possibilities:</p><pre><code class=language-rust>impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn expect(&amp;mut self, kind: SyntaxKind) {
        if self.at(kind) {
            self.bump();
        } else {
            self.error();
        }
    }

    pub(crate) fn error(&amp;mut self) {
        if !self.at_set(&amp;RECOVERY_SET) {
            self.bump();
        }
    }

    // snip

    fn at_set(&amp;mut self, set: &amp;[SyntaxKind]) -&gt; bool {
        self.peek().map_or(false, |k| set.contains(&amp;k))
    }

    // snip
}
</code></pre><p>We’ve reimplemented <code>Parser::expect</code> in terms of <code>Parser::error</code>, and we’ve also defined a small helper method that checks whether the parser is currently at a given set of <code>SyntaxKind</code>s. Let’s make use of this code:</p><pre><code class=language-rust>// expr.rs

fn lhs(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    let cm = match p.peek() {
        Some(SyntaxKind::Number) =&gt; literal(p),
        Some(SyntaxKind::Ident) =&gt; variable_ref(p),
        Some(SyntaxKind::Minus) =&gt; prefix_expr(p),
        Some(SyntaxKind::LParen) =&gt; paren_expr(p),
        _ =&gt; {
            p.error();
            return None;
        }
    };

    Some(cm)
}
</code></pre><p>We now have multiple failing tests! This is because we are trying to call <code>p.bump()</code> when we’ve arrived at the end of the input. We could add a check for if we are at the end of the input and not call <code>p.error()</code> then, but that would be incorrect. Think about it: if we’re trying to parse the left-hand side of an expression and are at the end of the input, that’s rightly an error. Instead, we should avoid calling <code>Parser::bump</code> in <code>Parser::error</code> if we’re at the end of the input.</p><pre><code class=language-rust>// parser.rs

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn error(&amp;mut self) {
        if !self.at_set(&amp;RECOVERY_SET) &amp;&amp; !self.at_end() {
            self.bump();
        }
    }

    // snip

    pub(crate) fn at_end(&amp;mut self) -&gt; bool {
        self.peek().is_none()
    }

    // snip
}
</code></pre><p>Our test is still failing because we’re calling <code>unwrap</code> in <code>variable_def</code>. We don’t need that anymore because we’re implementing proper error recovery:</p><pre><code class=language-rust>// stmt.rs

fn variable_def(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert!(p.at(SyntaxKind::LetKw));
    let m = p.start();
    p.bump();

    p.expect(SyntaxKind::Ident);
    p.expect(SyntaxKind::Equals);

    expr::expr(p);

    m.complete(p, SyntaxKind::VariableDef)
}
</code></pre><p>Running our tests shows that the parser is parsing the first variable definition correctly, but the second one is missing. This is because <code>grammar::root</code> only consumes a single statement. Let’s make it consume multiple:</p><pre><code class=language-rust>// grammar.rs

pub(crate) fn root(p: &amp;mut Parser) -&gt; CompletedMarker {
    let m = p.start();

    while !p.at_end() {
        stmt::stmt(p);
    }

    m.complete(p, SyntaxKind::Root)
}
</code></pre><p>Let’s write a test for that:</p><pre><code class=language-rust>#[cfg(test)]
mod tests {
    use crate::check;
    use expect_test::expect;

    #[test]
    fn parse_multiple_statements() {
        check(
            &quot;let a = 1\na&quot;,
            expect![[r#&quot;
Root@0..11
  VariableDef@0..10
    LetKw@0..3 &quot;let&quot;
    Whitespace@3..4 &quot; &quot;
    Ident@4..5 &quot;a&quot;
    Whitespace@5..6 &quot; &quot;
    Equals@6..7 &quot;=&quot;
    Whitespace@7..8 &quot; &quot;
    Literal@8..10
      Number@8..9 &quot;1&quot;
      Whitespace@9..10 &quot;\n&quot;
  VariableRef@10..11
    Ident@10..11 &quot;a&quot;&quot;#]],
        );
    }
}
</code></pre><p>Now both that test and <code>recover_on_let_token</code> pass!</p><pre><code class=language-->$ cargo t -q --lib

running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out


running 20 tests
....................
test result: ok. 20 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>Let’s wrap the tokens we <code>bump</code> in <code>Parser::error</code> in an <code>Error</code> node so we can distinguish them from tokens that are actually meant to be there:</p><pre><code class=language-rust>// parser.rs

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn error(&amp;mut self) {
        if !self.at_set(&amp;RECOVERY_SET) &amp;&amp; !self.at_end() {
            let m = self.start();
            self.bump();
            m.complete(self, SyntaxKind::Error);
        }
    }

    // snip
}
</code></pre><p>We don’t currently have any tests that contain erroneous tokens that end up being skipped, so all our tests are still passing.</p><p>Currently, <code>expr_binding_power</code> doesn’t do any error recovery directly; heck, we still have those comments in there reminding us to add it! Let’s remove them:</p><pre><code class=language-rust>// expr.rs

fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) -&gt; Option&lt;CompletedMarker&gt; {
    let mut lhs = lhs(p)?;

    loop {
        let op = match p.peek() {
            // snip
            _ =&gt; break,
        };

        // snip
    }

    Some(lhs)
}
</code></pre><p>What should we do in the case of the <code>break</code> when we’re working out the binding power of the current operator? One approach is to fall back to naive error recovery and loop until we find an operator. This brings with it all the problems of this strategy, though. Another option that’s <a href=https://github.com/rust-analyzer/rust-analyzer/blob/c01cd6e3ed0763f8e773c34dc76db0e39396133d/crates/parser/src/grammar/expressions.rs#L216>used by rust-analyzer</a> is to define a dummy <code>NotAnOp</code> variant of <code>BinaryOp</code> with a binding power of <code>(0, 1)</code>. Let’s try that out:</p><pre><code class=language-rust>fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) -&gt; Option&lt;CompletedMarker&gt; {
    let mut lhs = lhs(p)?;

    loop {
        let op = match p.peek() {
            Some(SyntaxKind::Plus) =&gt; BinaryOp::Add,
            Some(SyntaxKind::Minus) =&gt; BinaryOp::Sub,
            Some(SyntaxKind::Star) =&gt; BinaryOp::Mul,
            Some(SyntaxKind::Slash) =&gt; BinaryOp::Div,
            _ =&gt; {
                p.error();
                BinaryOp::NotAnOp
            }
        };

        // snip
    }

    Some(lhs)
}

// snip

enum BinaryOp {
    Add,
    Sub,
    Mul,
    Div,
    NotAnOp,
}

impl BinaryOp {
    fn binding_power(&amp;self) -&gt; (u8, u8) {
        match self {
            Self::NotAnOp =&gt; (0, 1),
            Self::Add | Self::Sub =&gt; (1, 2),
            Self::Mul | Self::Div =&gt; (3, 4),
        }
    }
}
</code></pre><p>If we run our tests we’ll see that a lot have panicked on <code>Option::unwrap</code>. This is due to the <code>p.bump()</code> call in <code>expr_binding_power</code> that panics when the parser is at the end of its input. We can solve this bug by adding an arm for <code>None</code>, and breaking out of the loop. It’s correct <em>not</em> to call <code>Parser::error</code> here, since parsing out a left-hand side and then being at the end of the input isn’t <em>bad</em> &ndash; it just means that this expression wasn’t binary.</p><pre><code class=language-rust>fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) -&gt; Option&lt;CompletedMarker&gt; {
    let mut lhs = lhs(p)?;

    loop {
        let op = match p.peek() {
            Some(SyntaxKind::Plus) =&gt; BinaryOp::Add,
            Some(SyntaxKind::Minus) =&gt; BinaryOp::Sub,
            Some(SyntaxKind::Star) =&gt; BinaryOp::Mul,
            Some(SyntaxKind::Slash) =&gt; BinaryOp::Div,
            None =&gt; break,
            _ =&gt; {
                p.error();
                BinaryOp::NotAnOp
            }
        };

        // snip
    }

    Some(lhs)
}
</code></pre><p>Some of our tests are now failing on a failed assertion that the parser is up to <code>)</code>. This is because we also need to return from <code>expr_binding_power</code> in that case; if we see a <code>)</code>, we know we’re done parsing this expression and can let the caller continue:</p><pre><code class=language-rust>fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) -&gt; Option&lt;CompletedMarker&gt; {
    let mut lhs = lhs(p)?;

    loop {
        let op = match p.peek() {
            Some(SyntaxKind::Plus) =&gt; BinaryOp::Add,
            Some(SyntaxKind::Minus) =&gt; BinaryOp::Sub,
            Some(SyntaxKind::Star) =&gt; BinaryOp::Mul,
            Some(SyntaxKind::Slash) =&gt; BinaryOp::Div,
            Some(SyntaxKind::RParen) | None =&gt; break,
            _ =&gt; {
                p.error();
                BinaryOp::NotAnOp
            }
        };

        // snip
    }

    Some(lhs)
}
</code></pre><p>We now have one failing test &ndash; <code>parse_multiple_statements</code>. Here’s the test’s input string:</p><pre><code>let a = 1
a
</code></pre><p>The parser goes along its way, <code>bump</code>ing <code>let</code>, <code>a</code> and <code>=</code>, at which point it needs an expression. It parses out <code>1</code> as <code>lhs</code>, and thinks ‘alright, I now need an operator’. It sees the <code>a</code> on the next line and thinks ‘oh, I didn’t expect this! I guess the user meant to type an operator, but typed <code>a</code> instead. Since this isn’t in <code>RECOVERY_SET</code> I’ll wrap this in an <code>Error</code> node and continue parsing’. The parser now tries to <code>bump</code> past the operator, even though it’s already done so in <code>Parser::error</code> and therefore is at the end of the input, causing a panic.</p><p>We have two options:</p><ul><li>detect the newline between <code>1</code> and <code>a</code> and decide that they must be separate expressions. This implies disallowing newlines between infix operators and their operands, which is a relatively common use-case (think of long expressions broken across multiple lines). We would want to handle newlines automatically, just like whitespace, which means we would have to create machinery that allows us to both check for newlines <em>while also</em> ignoring their existence. Furthermore, making Eldiro whitespace-sensitive is not a decision I take lightly; it’s nice to not have to worry or think about whitespace when you’re writing code, and instead let the autoformatter add it for you.</li><li>give up if we don’t see an operator and just return from the function. This means we’ll get worse error messages if the user mistypes an infix operator as another token.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></li></ul><p>To me, option two seems like the lesser evil, so that’s what we’ll implement. Let’s undo all those changes:</p><pre><code class=language-rust>fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) -&gt; Option&lt;CompletedMarker&gt; {
    let mut lhs = lhs(p)?;

    loop {
        let op = match p.peek() {
            Some(SyntaxKind::Plus) =&gt; BinaryOp::Add,
            Some(SyntaxKind::Minus) =&gt; BinaryOp::Sub,
            Some(SyntaxKind::Star) =&gt; BinaryOp::Mul,
            Some(SyntaxKind::Slash) =&gt; BinaryOp::Div,

            // We’re not at an operator; we don’t know what to do next, so we return and let the
            // caller decide.
            _ =&gt; break,
        };

        // snip
    }

    Some(lhs)
}

// snip

enum BinaryOp {
    Add,
    Sub,
    Mul,
    Div,
}

impl BinaryOp {
    fn binding_power(&amp;self) -&gt; (u8, u8) {
        match self {
            Self::Add | Self::Sub =&gt; (1, 2),
            Self::Mul | Self::Div =&gt; (3, 4),
        }
    }
}
</code></pre><p>The only sketchy non-recovering bit of the parser left is <code>paren_expr</code>, which <code>assert</code>s the existence of a closing parenthesis. Let’s write a test to make sure that we don’t get a panic on an unclosed parenthesis:</p><pre><code class=language-rust>#[cfg(test)]
mod tests {
    // snip

    #[test]
    fn parse_unclosed_parentheses() {
        check(
            &quot;(foo&quot;,
            expect![[r#&quot;
Root@0..4
  ParenExpr@0..4
    LParen@0..1 &quot;(&quot;
    VariableRef@1..4
      Ident@1..4 &quot;foo&quot;&quot;#]],
        );
    }
}
</code></pre><pre><code class=language-->$ cargo t -q --lib

running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out


running 21 tests
..............F......
failures:

---- grammar::expr::tests::parse_unclosed_parentheses stdout ----
thread 'grammar::expr::tests::parse_unclosed_parentheses' panicked at 'assertion failed: p.at(SyntaxKind::RParen)', crates/parser/src/grammar/expr.rs:122:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace


failures:
    grammar::expr::tests::parse_unclosed_parentheses

test result: FAILED. 20 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>As expected, the parser panicked on that <code>assert</code>. Let’s replace the <code>assert</code>-and-<code>bump</code> dance with a simple call to <code>expect</code>:</p><pre><code class=language-rust>fn paren_expr(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert!(p.at(SyntaxKind::LParen));

    let m = p.start();
    p.bump();
    expr_binding_power(p, 0);
    p.expect(SyntaxKind::RParen);

    m.complete(p, SyntaxKind::ParenExpr)
}
</code></pre><pre><code class=language-->$ cargo t -q --lib

running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out


running 21 tests
.....................
test result: ok. 21 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>Although we’re done with error recovery for now, this topic is deep and we’ll have to consider it in all changes we make to the parser in future.</p><h1 id=implementing-error-reporting>Implementing error reporting</h1><p>Now that our parser doesn’t explode when the user makes a typo, we’re ready to move on to the next topic: error reporting. In cases such as the missing parenthesis, the error of not including the parenthesis is <em>silently ignored.</em> A way to ensure parse errors are being created properly is to include them below the syntax tree in tests; with this change all inputs that have parse errors have to document them.</p><p>One aspect of good error messages is that they show what tokens the parser was expecting to see in the situation that caused the error. This gives the user a hint as to what they might try to fix the error. To implement this behaviour, the parser has to track which tokens it’s expecting throughout the parsing process; when it encounters an error this set can be displayed. We can use a technique <a href="https://www.reddit.com/r/rust/comments/jh69jx/blog_post_introducing_ungrammar/ga1gms8?utm_source=share&utm_medium=web2x&context=3">mentioned on Reddit</a> by u/matklad:</p><ul><li>Every time <code>Parser::at</code> is called we’ll add the <code>SyntaxKind</code> being enquired about to an <code>expected_kinds</code> field on <code>Parser</code></li><li>Whenever a token is added to the syntax tree the set is cleared</li></ul><p>Let’s write this now:</p><pre><code class=language-rust>// parser.rs

pub(crate) struct Parser&lt;'t, 'input&gt; {
    source: Source&lt;'t, 'input&gt;,
    events: Vec&lt;Event&gt;,
    expected_kinds: Vec&lt;SyntaxKind&gt;,
}

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    pub(crate) fn new(source: Source&lt;'t, 'input&gt;) -&gt; Self {
        Self {
            source,
            events: Vec::new(),
            expected_kinds: Vec::new(),
        }
    }

    // snip

    pub(crate) fn bump(&amp;mut self) {
        self.expected_kinds.clear();
        self.source.next_token().unwrap();
        self.events.push(Event::AddToken);
    }

    pub(crate) fn at(&amp;mut self, kind: SyntaxKind) -&gt; bool {
        self.expected_kinds.push(kind);
        self.peek() == Some(kind)
    }

    // snip
}
</code></pre><p>Throughout <code>grammar</code> we often <code>match</code> on <code>p.peek()</code> to determine what to do next. Although this results in easy-to-read code, it is incompatible with this new approach. How is the parser meant to manage <code>expected_kinds</code> if it can’t know which arm of the <code>match</code> is being run and which ones have been tried before? We’ll have to convert all these <code>match</code>es to <code>if else</code> chains that use <code>Parser::at</code>.</p><p>To ensure we don’t accidentally use the old <code>match</code> approach in future, let’s make <code>Parser::peek</code> private:</p><pre><code class=language-rust>impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    fn peek(&amp;mut self) -&gt; Option&lt;SyntaxKind&gt; {
        self.source.peek_kind()
    }
}
</code></pre><p>Let’s update all the usages of <code>Parser::peek</code> now:</p><pre><code class=language-rust>// expr.rs

fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) -&gt; Option&lt;CompletedMarker&gt; {
    let mut lhs = lhs(p)?;

    loop {
        let op = if p.at(SyntaxKind::Plus) {
            BinaryOp::Add
        } else if p.at(SyntaxKind::Minus) {
            BinaryOp::Sub
        } else if p.at(SyntaxKind::Star) {
            BinaryOp::Mul
        } else if p.at(SyntaxKind::Slash) {
            BinaryOp::Div
        } else {
            // We’re not at an operator; we don’t know what to do next, so we return and let the
            // caller decide.
            break;
        };

        // snip
    }

    Some(lhs)
}

fn lhs(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    let cm = if p.at(SyntaxKind::Number) {
        literal(p)
    } else if p.at(SyntaxKind::Ident) {
        variable_ref(p)
    } else if p.at(SyntaxKind::Minus) {
        prefix_expr(p)
    } else if p.at(SyntaxKind::LParen) {
        paren_expr(p)
    } else {
        p.error();
        return None;
    };

    Some(cm)
}
</code></pre><pre><code class=language-rust>// stmt.rs

pub(super) fn stmt(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    if p.at(SyntaxKind::LetKw) {
        Some(variable_def(p))
    } else {
        expr::expr(p)
    }
}
</code></pre><p>That’s &mldr; not that bad. Most long <code>if else</code> chains look horribly ugly, but this one is ok.</p><p>The next change we need to make is emit errors from the parser. For that we’ll need a type that can represent a parse error:</p><pre><code class=language-rust>// parser.rs

pub(crate) mod marker;

mod parse_error;
pub(crate) use parse_error::ParseError;

use crate::event::Event;
use crate::grammar;
use crate::source::Source;
use marker::Marker;
use syntax::SyntaxKind;
</code></pre><pre><code class=language-rust>// crates/parser/src/parser/parse_error.rs

use syntax::SyntaxKind;
use text_size::TextRange;

#[derive(Debug, PartialEq)]
pub(crate) struct ParseError {
    pub(super) expected: Vec&lt;SyntaxKind&gt;,
    pub(super) found: Option&lt;SyntaxKind&gt;,
    pub(super) range: TextRange,
}
</code></pre><pre><code class=language-toml># crates/parser/Cargo.toml

[dependencies]
drop_bomb = &quot;0.1.5&quot;
lexer = {path = &quot;../lexer&quot;}
rowan = &quot;0.10.0&quot;
syntax = {path = &quot;../syntax&quot;}
text-size = &quot;1.0.0&quot;
</code></pre><p>We’re using <code>TextRange</code> from the text-size crate instead of <code>std::ops::Range&lt;usize></code> because <code>TextRange</code> uses <code>u32</code> internally, making its size in memory smaller.</p><p>The way we’ll communicate the parse errors the parser finds to other code is through the existing <code>Event</code> infrastructure. Let’s create <code>Event::Error</code>:</p><pre><code class=language-rust>// event.rs

use crate::parser::ParseError;
use syntax::SyntaxKind;

#[derive(Debug, PartialEq)]
pub(crate) enum Event {
    StartNode {
        kind: SyntaxKind,
        forward_parent: Option&lt;usize&gt;,
    },
    AddToken,
    FinishNode,
    Error(ParseError),
    Placeholder,
}
</code></pre><p>We can push the <code>Event::Error</code> event when the parser encounters an error (which we’ve conveniently centralised into the <code>Parser::error</code> method):</p><pre><code class=language-rust>// parser.rs

use crate::event::Event;
use crate::grammar;
use crate::source::Source;
use marker::Marker;
use std::mem;
use syntax::SyntaxKind;

// snip

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn error(&amp;mut self) {
        let found = self.peek();
        self.events.push(Event::Error(ParseError {
            expected: mem::take(&amp;mut self.expected_kinds),
            found,
            range: todo!(),
        }));

        if !self.at_set(&amp;RECOVERY_SET) &amp;&amp; !self.at_end() {
            let m = self.start();
            self.bump();
            m.complete(self, SyntaxKind::Error);
        }
    }

    // snip
}
</code></pre><p>That <code>mem::take</code> function returns what is passed in, and replaces the thing that was passed in with its default value. In other words, it lets us concisely take ownership of <code>self.expected_kinds</code> while replacing it with a new empty <code>Vec</code>. We don’t have a way to get the range of the current token, though.</p><p>Let’s add a <code>range</code> field to <code>Token</code>:</p><pre><code class=language-rust>// crates/lexer/src/lib.rs

use logos::Logos;
use text_size::TextRange;

// snip

#[derive(Debug, PartialEq)]
pub struct Token&lt;'a&gt; {
    pub kind: TokenKind,
    pub text: &amp;'a str,
    pub range: TextRange,
}
</code></pre><pre><code class=language-toml># crates/lexer/Cargo.toml

[dependencies]
logos = &quot;0.11.4&quot;
text-size = &quot;1.0.0&quot;
</code></pre><p>We need to update <code>Lexer</code> to emit ranges:</p><pre><code class=language-rust>// lib.rs

use logos::Logos;
use std::convert::TryFrom;
use std::ops::Range as StdRange;
use text_size::{TextRange, TextSize};

// snip

impl&lt;'a&gt; Iterator for Lexer&lt;'a&gt; {
    type Item = Token&lt;'a&gt;;

    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
        let kind = self.inner.next()?;
        let text = self.inner.slice();

        let range = {
            let StdRange { start, end } = self.inner.span();
            let start = TextSize::try_from(start).unwrap();
            let end = TextSize::try_from(end).unwrap();

            TextRange::new(start, end)
        };

        Some(Self::Item { kind, text, range })
    }
}
</code></pre><pre><code class=language-rust>// token_kind.rs

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Lexer;

    fn check(input: &amp;str, kind: TokenKind) {
        let mut lexer = Lexer::new(input);

        let token = lexer.next().unwrap();
        assert_eq!(token.kind, kind);
        assert_eq!(token.text, input);
    }

    // snip
}
</code></pre><p>To access these ranges from the parser, we need to change <code>Source</code>’s API:</p><pre><code class=language-rust>// source.rs

impl&lt;'t, 'input&gt; Source&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn peek_token(&amp;mut self) -&gt; Option&lt;&amp;Token&gt; {
        self.eat_trivia();
        self.peek_token_raw()
    }

    // snip

    fn peek_kind_raw(&amp;self) -&gt; Option&lt;SyntaxKind&gt; {
        self.peek_token_raw()
            .map(|Token { kind, .. }| (*kind).into())
    }

    fn peek_token_raw(&amp;self) -&gt; Option&lt;&amp;Token&gt; {
        self.tokens.get(self.cursor)
    }
}
</code></pre><p>And use it from <code>Parser::error</code>:</p><pre><code class=language-rust>use crate::event::Event;
use crate::grammar;
use crate::source::Source;
use lexer::Token;
use marker::Marker;
use std::mem;
use syntax::SyntaxKind;

// snip

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn error(&amp;mut self) {
        let current_token = self.source.peek_token();

        let (found, range) = current_token.map_or_else(
            || (None, todo!()),
            |Token { kind, range, .. }| (Some((*kind).into()), *range),
        );

        self.events.push(Event::Error(ParseError {
            expected: mem::take(&amp;mut self.expected_kinds),
            found,
            range,
        }));

        if !self.at_set(&amp;RECOVERY_SET) &amp;&amp; !self.at_end() {
            let m = self.start();
            self.bump();
            m.complete(self, SyntaxKind::Error);
        }
    }

    // snip
}
</code></pre><p>Take a look at that <code>todo!()</code> though; what range do we use for the parse error if we’re at the end of the input? To me the most sensible answer is to use the range of the last token. Let’s add another method to <code>Source</code>:</p><pre><code class=language-rust>use lexer::Token;
use syntax::SyntaxKind;
use text_size::TextRange;

// snip

impl&lt;'t, 'input&gt; Source&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn last_token_range(&amp;self) -&gt; Option&lt;TextRange&gt; {
        self.tokens.last().map(|Token { range, .. }| *range)
    }

    // snip
}
</code></pre><p>We return an <code>Option</code> because it isn’t up to <code>Source</code> to handle the case in which the input is empty; we’ll leave that up to the parser. Speaking of which, <code>Parser:error</code> won’t ever be called when the input is empty because we know that <code>grammar::root</code> is fine with empty inputs. Thus, it is safe to unwrap:</p><pre><code class=language-rust>impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn error(&amp;mut self) {
        let current_token = self.source.peek_token();

        let (found, range) = current_token.map_or_else(
            // If we’re at the end of the input we use the range of the very last token in the
            // input.
            || (None, self.source.last_token_range().unwrap()),
            |Token { kind, range, .. }| (Some((*kind).into()), *range),
        );

        self.events.push(Event::Error(ParseError {
            expected: mem::take(&amp;mut self.expected_kinds),
            found,
            range,
        }));

        if !self.at_set(&amp;RECOVERY_SET) &amp;&amp; !self.at_end() {
            let m = self.start();
            self.bump();
            m.complete(self, SyntaxKind::Error);
        }
    }

    // snip
}
</code></pre><p>We have one last compilation error in <code>Sink</code>, which we need to change to maintain a list of parse errors:</p><pre><code class=language-rust>// sink.rs

use super::event::Event;
use crate::parser::ParseError;
use lexer::Token;
use rowan::{GreenNode, GreenNodeBuilder, Language};
use std::mem;
use syntax::{EldiroLanguage, SyntaxKind};

pub(crate) struct Sink&lt;'t, 'input&gt; {
    builder: GreenNodeBuilder&lt;'static&gt;,
    tokens: &amp;'t [Token&lt;'input&gt;],
    cursor: usize,
    events: Vec&lt;Event&gt;,
    errors: Vec&lt;ParseError&gt;,
}

impl&lt;'t, 'input&gt; Sink&lt;'t, 'input&gt; {
    pub(crate) fn new(tokens: &amp;'t [Token&lt;'input&gt;], events: Vec&lt;Event&gt;) -&gt; Self {
        Self {
            builder: GreenNodeBuilder::new(),
            tokens,
            cursor: 0,
            events,
            errors: Vec::new(),
        }
    }

    pub(crate) fn finish(mut self) -&gt; GreenNode {
        for idx in 0..self.events.len() {
            match mem::replace(&amp;mut self.events[idx], Event::Placeholder) {
                // snip
                Event::Error(error) =&gt; self.errors.push(error),
                // snip
            }

            self.eat_trivia();
        }

        self.builder.finish()
    }

    // snip

    fn token(&amp;mut self) {
        let Token { kind, text, .. } = self.tokens[self.cursor];

        self.builder
            .token(EldiroLanguage::kind_to_raw(kind.into()), text.into());

        self.cursor += 1;
    }
}
</code></pre><p>Fixing these basic compilation errors has revealed a borrow checker error; fortunately for us, this is trivial to fix by converting the call to <code>Option::map_or_else</code> in <code>Parser::error</code> to an <code>if let</code>:</p><pre><code class=language-rust>// parser.rs

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn error(&amp;mut self) {
        let current_token = self.source.peek_token();

        let (found, range) = if let Some(Token { kind, range, .. }) = current_token {
            (Some((*kind).into()), *range)
        } else {
            // If we’re at the end of the input we use the range of the very last token in the
            // input.
            (None, self.source.last_token_range().unwrap())
        };

        self.events.push(Event::Error(ParseError {
            expected: mem::take(&amp;mut self.expected_kinds),
            found,
            range,
        }));

        if !self.at_set(&amp;RECOVERY_SET) &amp;&amp; !self.at_end() {
            let m = self.start();
            self.bump();
            m.complete(self, SyntaxKind::Error);
        }
    }

    // snip
}
</code></pre><p>Although we now have a <code>Vec&lt;ParseError></code>, we aren’t using it! Let’s add it as a field to <code>Parse</code>, which we’ll construct directly from <code>Sink::finish</code>:</p><pre><code class=language-rust>// lib.rs

use lexer::Lexer;
use parser::{ParseError, Parser};
use rowan::GreenNode;
use sink::Sink;
use source::Source;
use syntax::SyntaxNode;

pub fn parse(input: &amp;str) -&gt; Parse {
    let tokens: Vec&lt;_&gt; = Lexer::new(input).collect();
    let source = Source::new(&amp;tokens);
    let parser = Parser::new(source);
    let events = parser.parse();
    let sink = Sink::new(&amp;tokens, events);

    sink.finish()
}

pub struct Parse {
    green_node: GreenNode,
    errors: Vec&lt;ParseError&gt;,
}
</code></pre><pre><code class=language-rust>// sink.rs

use crate::event::Event;
use crate::parser::ParseError;
use crate::Parse;
use lexer::Token;
use rowan::{GreenNodeBuilder, Language};
use std::mem;
use syntax::{EldiroLanguage, SyntaxKind};

// snip

impl&lt;'t, 'input&gt; Sink&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn finish(mut self) -&gt; Parse {
        // snip

        Parse {
            green_node: self.builder.finish(),
            errors: self.errors,
        }
    }

    // snip
}
</code></pre><p>We need to be able to display parse errors, both for display to the user and for usage in tests. Let’s write a test to start:</p><pre><code class=language-rust>// parse_error.rs

#[cfg(test)]
mod tests {
    use super::*;
    use std::ops::Range as StdRange;

    fn check(
        expected: Vec&lt;SyntaxKind&gt;,
        found: Option&lt;SyntaxKind&gt;,
        range: StdRange&lt;u32&gt;,
        output: &amp;str,
    ) {
        let error = ParseError {
            expected,
            found,
            range: {
                let start = range.start.into();
                let end = range.end.into();
                TextRange::new(start, end)
            },
        };

        assert_eq!(format!(&quot;{}&quot;, error), output);
    }

    #[test]
    fn one_expected_did_find() {
        check(
            vec![SyntaxKind::Equals],
            Some(SyntaxKind::Ident),
            10..20,
            &quot;error at 10..20: expected ‘=’, but found identifier&quot;,
        );
    }
}
</code></pre><p>Let’s write a dead-simple initial implementation:</p><pre><code class=language-rust>use std::fmt;
use syntax::SyntaxKind;
use text_size::TextRange;

// snip

impl fmt::Display for ParseError {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        write!(
            f,
            &quot;error at {}..{}: expected {}, but found {}&quot;,
            u32::from(self.range.start()),
            u32::from(self.range.end()),
            self.expected[0],
            self.found.unwrap(),
        )
    }
}
</code></pre><p>This depends on a <code>Display</code> implementation on <code>SyntaxKind</code>; we can write that now:</p><pre><code class=language-rust>// crates/syntax/src/lib.rs

use lexer::TokenKind;
use num_derive::{FromPrimitive, ToPrimitive};
use num_traits::{FromPrimitive, ToPrimitive};
use std::fmt;

// snip

impl fmt::Display for SyntaxKind {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        f.write_str(match self {
            SyntaxKind::Whitespace =&gt; &quot;whitespace&quot;,
            SyntaxKind::FnKw =&gt; &quot;‘fn’&quot;,
            SyntaxKind::LetKw =&gt; &quot;‘let’&quot;,
            SyntaxKind::Ident =&gt; &quot;identifier&quot;,
            SyntaxKind::Number =&gt; &quot;number&quot;,
            SyntaxKind::Plus =&gt; &quot;‘+’&quot;,
            SyntaxKind::Minus =&gt; &quot;‘-’&quot;,
            SyntaxKind::Star =&gt; &quot;‘*’&quot;,
            SyntaxKind::Slash =&gt; &quot;‘/’&quot;,
            SyntaxKind::Equals =&gt; &quot;‘=’&quot;,
            SyntaxKind::LParen =&gt; &quot;‘(’&quot;,
            SyntaxKind::RParen =&gt; &quot;‘)’&quot;,
            SyntaxKind::LBrace =&gt; &quot;‘{’&quot;,
            SyntaxKind::RBrace =&gt; &quot;‘}’&quot;,
            SyntaxKind::Comment =&gt; &quot;comment&quot;,
            _ =&gt; unreachable!(),
        })
    }
}
</code></pre><p>Let’s verify that parse errors are emitted properly by including them in tests:</p><pre><code class=language-rust>// crates/parser/src/lib.rs

impl Parse {
    pub fn debug_tree(&amp;self) -&gt; String {
        let mut s = String::new();

        let syntax_node = SyntaxNode::new_root(self.green_node.clone());
        let tree = format!(&quot;{:#?}&quot;, syntax_node);

        // We cut off the last byte because formatting the SyntaxNode adds on a newline at the end.
        s.push_str(&amp;tree[0..tree.len() - 1]);

        for error in &amp;self.errors {
            s.push_str(&amp;format!(&quot;\n{}&quot;, error));
        }

        s
    }
}
</code></pre><p>We get two test failures, one of which is from the <code>unwrap</code> in <code>ParseError</code>’s <code>Display</code> implementation, while the other is from the error message not being in the test’s expected text. Let’s write a test for the case where the error is at the end of the input and <code>found</code> is therefore <code>None</code>:</p><pre><code class=language-rust>// parse_error.rs

#[cfg(test)]
mod tests {
    // snip

    #[test]
    fn one_expected_did_not_find() {
        check(
            vec![SyntaxKind::RParen],
            None,
            5..6,
            &quot;error at 5..6: expected ‘)’&quot;,
        );
    }
}
</code></pre><p>To solve this, we can change the <code>Display</code> implementation to check if <code>found</code> is <code>None</code>:</p><pre><code class=language-rust>impl fmt::Display for ParseError {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        write!(
            f,
            &quot;error at {}..{}: expected {}&quot;,
            u32::from(self.range.start()),
            u32::from(self.range.end()),
            self.expected[0]
        )?;

        if let Some(found) = self.found {
            write!(f, &quot;, but found {}&quot;, found)?;
        }

        Ok(())
    }
}
</code></pre><p>We should write a test to cover the case where <code>expected</code> has more than one kind:</p><pre><code class=language-rust>#[cfg(test)]
mod tests {
    // snip

    #[test]
    fn multiple_expected_did_find() {
        check(
            vec![
                SyntaxKind::Number,
                SyntaxKind::Ident,
                SyntaxKind::Minus,
                SyntaxKind::LParen,
            ],
            Some(SyntaxKind::LetKw),
            100..105,
            &quot;error at 100..105: expected number, identifier, ‘-’ or ‘(’, but found ‘let’&quot;,
        );
    }
}
</code></pre><p>This can be implemented with a loop:</p><pre><code class=language-rust>impl fmt::Display for ParseError {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        write!(
            f,
            &quot;error at {}..{}: expected &quot;,
            u32::from(self.range.start()),
            u32::from(self.range.end()),
        )?;

        let num_expected = self.expected.len();
        let is_first = |idx| idx == 0;
        let is_last = |idx| idx == num_expected - 1;

        for (idx, expected_kind) in self.expected.iter().enumerate() {
            if is_first(idx) {
                write!(f, &quot;{}&quot;, expected_kind)?;
            } else if is_last(idx) {
                write!(f, &quot; or {}&quot;, expected_kind)?;
            } else {
                write!(f, &quot;, {}&quot;, expected_kind)?;
            }
        }

        if let Some(found) = self.found {
            write!(f, &quot;, but found {}&quot;, found)?;
        }

        Ok(())
    }
}
</code></pre><p>Let’s add a test for when two <code>SyntaxKind</code> are expected to make sure that <code>or</code> is added between them instead of a comma:</p><pre><code class=language-rust>#[cfg(test)]
mod tests {
    // snip

    #[test]
    fn two_expected_did_find() {
        check(
            vec![SyntaxKind::Plus, SyntaxKind::Minus],
            Some(SyntaxKind::Equals),
            0..1,
            &quot;error at 0..1: expected ‘+’ or ‘-’, but found ‘=’&quot;,
        );
    }

    // snip
}
</code></pre><p>Looking through the failed tests shows that the error messages are being generated properly. We can update these automatically using expect-test:</p><pre><code class=language-->$ UPDATE_EXPECT=1 cargo t -q --lib

running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out


running 25 tests
.........................
test result: ok. 25 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>Let’s try out our error recovery and reporting in the REPL:</p><pre><code class=language-->$ cargo r -q
→ (1+
Root@0..4
  ParenExpr@0..4
    LParen@0..1 &quot;(&quot;
    InfixExpr@1..4
      Literal@1..2
        Number@1..2 &quot;1&quot;
      Plus@2..3 &quot;+&quot;
      Whitespace@3..4 &quot;\n&quot;
error at 3..4: expected number, identifier, ‘-’ or ‘(’
error at 3..4: expected ‘+’, ‘-’, ‘*’, ‘/’ or ‘)’
</code></pre><p>The first of those two parse errors makes sense, because an expression is expected after an operator. The second one, not so much; why would you add another operator after an existing operator?</p><p>It’s non-obvious why the parser is emitting the second error message (apart from the <code>)</code>); to understand why it’s doing this we should keep the basic structure of <code>expr_binding_power</code> in mind:</p><pre><code class=language-rust>fn expr_binding_power() -&gt; Option&lt;CompletedMarker&gt; {
    let lhs = lhs()?;

    loop {
        let op = get_operator();
        expr_binding_power();
    }

    Some(lhs)
}
</code></pre><p>Let’s imagine we’re parsing the <code>1+</code> in <code>(1+</code>. We successfully get a left-hand side, and now enter the loop and extract an operator. We now recurse, and fail to get a left-hand side. This means we return <code>None</code> from this inner call. Here’s where the problem lies: rather than exiting because we couldn’t get a right-hand side, we just loop around again and try to get another operator. Let’s add a check to <code>expr_binding_power</code> to fix this issue:</p><pre><code class=language-rust>// expr.rs

fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) -&gt; Option&lt;CompletedMarker&gt; {
    let mut lhs = lhs(p)?;

    loop {
        // snip

        let m = lhs.precede(p);
        let parsed_rhs = expr_binding_power(p, right_binding_power).is_some();
        lhs = m.complete(p, SyntaxKind::InfixExpr);

        if !parsed_rhs {
            break;
        }
    }

    Some(lhs)
}
</code></pre><p>Instead of manually typing out that scenario from before in the REPL to find out if we’ve squashed the bug, we can write a test to ensure we never regress on this specific scenario:</p><pre><code class=language-rust>#[cfg(test)]
mod tests {
    // snip

    #[test]
    fn do_not_parse_operator_if_gettting_rhs_failed() {
        check(
            &quot;(1+&quot;,
            expect![[r#&quot;
Root@0..3
  ParenExpr@0..3
    LParen@0..1 &quot;(&quot;
    InfixExpr@1..3
      Literal@1..2
        Number@1..2 &quot;1&quot;
      Plus@2..3 &quot;+&quot;
error at 2..3: expected number, identifier, ‘-’ or ‘(’
error at 2..3: expected ‘)’&quot;#]],
        );
    }

    // snip
}
</code></pre><p>It makes sense that we would get two errors, since there really are two errors here: that of the binary expression missing a right-hand side, and that of an unclosed parenthesis.</p><pre><code class=language-->$ cargo t -q --lib

running 18 tests
..................
test result: ok. 18 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out


running 26 tests
..........................
test result: ok. 26 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><h1 id=refactoring>Refactoring</h1><p>We’re almost done! Currently, Eldiro uses <code>TokenKind</code>s exclusively in the lexer, and converts them to <code>SyntaxKind</code>s for use everywhere else. We’d be better off with using <code>TokenKind</code> for things that can’t be any of the node variants exclusive to <code>SyntaxKind</code>, such as the <code>SyntaxKind</code> passed into <code>Parser::at</code>. This is a straightforward change to make, so I’ll just show the changed sections without any explanation:</p><pre><code class=language-rust>// grammar.rs

use crate::parser::marker::CompletedMarker;
use crate::parser::Parser;
use lexer::TokenKind;
use syntax::SyntaxKind;
</code></pre><pre><code class=language-rust>// parser.rs

use crate::event::Event;
use crate::grammar;
use crate::source::Source;
use lexer::{Token, TokenKind};
use marker::Marker;
use std::mem;
use syntax::SyntaxKind;

const RECOVERY_SET: [TokenKind; 1] = [TokenKind::LetKw];

pub(crate) struct Parser&lt;'t, 'input&gt; {
    source: Source&lt;'t, 'input&gt;,
    events: Vec&lt;Event&gt;,
    expected_kinds: Vec&lt;TokenKind&gt;,
}

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    pub(crate) fn expect(&amp;mut self, kind: TokenKind) {
        // snip
    }

    pub(crate) fn error(&amp;mut self) {
        let current_token = self.source.peek_token();

        let (found, range) = if let Some(Token { kind, range, .. }) = current_token {
            (Some(*kind), *range)
        } else {
            // If we’re at the end of the input we use the range of the very last token in the
            // input.
            (None, self.source.last_token_range().unwrap())
        };

        // snip
    }

    // snip

    pub(crate) fn at(&amp;mut self, kind: TokenKind) -&gt; bool {
        // snip
    }

    fn at_set(&amp;mut self, set: &amp;[TokenKind]) -&gt; bool {
        // snip
    }

    // snip

    fn peek(&amp;mut self) -&gt; Option&lt;TokenKind&gt; {
        // snip
    }
}
</code></pre><pre><code class=language-rust>// crates/lexer/src/token_kind.rs

use logos::Logos;
use std::fmt;

// snip

impl TokenKind {
    pub fn is_trivia(self) -&gt; bool {
        matches!(self, Self::Whitespace | Self::Comment)
    }
}

impl fmt::Display for TokenKind {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        f.write_str(match self {
            Self::Whitespace =&gt; &quot;whitespace&quot;,
            Self::FnKw =&gt; &quot;‘fn’&quot;,
            Self::LetKw =&gt; &quot;‘let’&quot;,
            Self::Ident =&gt; &quot;identifier&quot;,
            Self::Number =&gt; &quot;number&quot;,
            Self::Plus =&gt; &quot;‘+’&quot;,
            Self::Minus =&gt; &quot;‘-’&quot;,
            Self::Star =&gt; &quot;‘*’&quot;,
            Self::Slash =&gt; &quot;‘/’&quot;,
            Self::Equals =&gt; &quot;‘=’&quot;,
            Self::LParen =&gt; &quot;‘(’&quot;,
            Self::RParen =&gt; &quot;‘)’&quot;,
            Self::LBrace =&gt; &quot;‘{’&quot;,
            Self::RBrace =&gt; &quot;‘}’&quot;,
            Self::Comment =&gt; &quot;comment&quot;,
            Self::Error =&gt; &quot;an unrecognized token&quot;,
        })
    }
}
</code></pre><p>Delete <code>SyntaxKind::is_trivia</code> and <code>SyntaxKind</code>’s <code>Display</code> implementation. Replace all uses of <code>SyntaxKind</code> with <code>TokenKind</code> in <code>parse_error.rs</code> and <code>sink.rs</code>. Now follow the Rust compiler’s errors to fix all the type errors that have now cropped up across the project. Sorry for this having a bit of a ‘this is left as an exercise for the reader’ feel, but I think that making this part any longer than it already is for the sake of simple substitutions is not a good idea.</p><p>Take a look at <a href=https://github.com/arzg/eldiro/commit/dbc2abb57a392e38b08e62fde0a1b7f8771b2720>the diff</a> of the commit that makes this change if you get confused or stuck.</p><h1 id=conclusion>Conclusion</h1><p>Hopefully this wasn’t too difficult to follow! We’ll create structures to work with parsed code in the next part.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>I mention this because, in my experience, this case is very rare; my most common typos with infix operators are mistyping one for the other, not as something completely different.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></main><nav class=page-navigation><div class=prev><p class=hint>Previously</p><a href=https://arzg.github.io/lang/17/>Part Seventeen: Crates</a></div><div class=next><p class=hint>Next up</p><a href=https://arzg.github.io/lang/19/>Part Nineteen: Code Representations</a></div><div style=clear:both></div></nav></body></html>