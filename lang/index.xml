<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Make A Language on
arzg’s website</title><link>https://arzg.github.io/lang/</link><description>
Recent content
in Make A Language
on arzg’s website</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><atom:link href="https://arzg.github.io/lang/index.xml" rel="self" type="application/rss+xml"/><item><title>Part Twenty: Testing</title><link>https://arzg.github.io/lang/20/</link><pubDate>
Wed, 27 Jan 2021 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/20/</guid><description>
I was disciplined with my TDD throughout the early parts of this series &amp;ndash; I think this was helpful. Unfortunately, testing has fallen by the wayside in some recent parts; especially the last one. I would like to get back into the habit of TDD, and so I should add tests to areas of the codebase that are missing them.
A weird compilation failure First off, a small erratum: it turns out that Eldiro fails to compile when the entire workspace’s tests are run:</description></item><item><title>Part Nineteen: Code Representations</title><link>https://arzg.github.io/lang/19/</link><pubDate>
Sun, 24 Jan 2021 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/19/</guid><description>
So far we have only used two different data structures to represent code:
abstract syntax trees concrete syntax trees An abstract syntax tree is a data structure that represents the bare minimum about a chunk of code. We used ASTs in the early parts of this series prior to the Rowan rewrite. For example, here’s an AST that represents variable definitions:
struct VariableDef { name: String, value: Expr, } enum Expr { // snip } Note how it doesn’t include the let token or the =, and ignores trivia like whitespace and comments; it’s abstract, and only contains the information necessary to implement, say, a compiler.</description></item><item><title>Part Eighteen: Errors</title><link>https://arzg.github.io/lang/18/</link><pubDate>
Mon, 21 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/18/</guid><description>
So far, our parser has only concerned itself with input that is correct. In a world of IDEs and language servers, however, the input to our parser will be wrong more often than not. Therefore, it is important that our parser can:
recover gracefully from errors infer as detailed a syntax tree from the input as possible report errors in a user-friendly manner Unfortunately for us, the only thing our parser currently supports is arithmetic expressions, which don’t make error recovery techniques easy to demonstrate.</description></item><item><title>Part Seventeen: Crates</title><link>https://arzg.github.io/lang/17/</link><pubDate>
Fri, 18 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/17/</guid><description>
I’m not a fan of how, currently, all the submodules of crate::parser can access the internals of our parser. This access makes sense for marker.rs, but not for, say, expr.rs. These other modules should have to go through the parser’s API. We can enforce these sorts of visibility issues by breaking our project up into crates.
Extracting the lexer The first part of Eldiro we’ll create a separate crate for is the lexer.</description></item><item><title>Part Sixteen: Refactoring</title><link>https://arzg.github.io/lang/16/</link><pubDate>
Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/16/</guid><description>
Refactoring expr_binding_power The right-hand side of the let lhs = ... in expr_binding_power is getting quite long, so let’s extract it to its own function:
// expr.rs use super::marker::CompletedMarker; use super::Parser; use crate::lexer::SyntaxKind; // snip fn expr_binding_power(p: &amp;amp;mut Parser, minimum_binding_power: u8) { let mut lhs = if let Some(lhs) = lhs(p) { lhs } else { return; // we’ll handle errors later. }; // snip } fn lhs(p: &amp;amp;mut Parser) -&amp;gt; Option&amp;lt;CompletedMarker&amp;gt; { let cm = match p.</description></item><item><title>Part Fifteen: Markers</title><link>https://arzg.github.io/lang/15/</link><pubDate>
Wed, 16 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/15/</guid><description>
A ‘marker’ is an abstraction over Rowan that makes working with it nicer, and also allows for some fancier parsing techniques. You can think of them as a fancy version of the checkpoints we’ve been using up to this point. Here’s a rough sketch of the API we’ll create:
impl Parser { fn start(&amp;amp;mut self) -&amp;gt; Marker; } struct Marker { ... } impl Marker { fn complete(self, p: &amp;amp;mut Parser, kind: SyntaxKind) -&amp;gt; CompletedMarker; } struct CompletedMarker { .</description></item><item><title>Part Fourteen: Comments</title><link>https://arzg.github.io/lang/14/</link><pubDate>
Thu, 10 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/14/</guid><description>
The first thing we need to do is teach the lexer to recognise comments. We’ll begin with a test:
// lexer.rs #[cfg(test)] mod tests { // snip #[test] fn lex_comment() { check(&amp;quot;# foo&amp;quot;, SyntaxKind::Comment); } } Here’s the implementation:
pub(crate) enum SyntaxKind { // snip #[regex(&amp;quot;#.*&amp;quot;)] Comment, #[error] Error, Root, BinaryExpr, PrefixExpr, } Take note of how we aren’t using #[logos::skip] here; instead, we are explicitly including comments in the output of our lexer.</description></item><item><title>Part Thirteen: Whitespace &amp; Events</title><link>https://arzg.github.io/lang/13/</link><pubDate>
Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/13/</guid><description>
The simple but annoying approach We could check for the presence of whitespace after every token:
// do some stuff if p.peek() == Some(SyntaxKind::Whitespace) { p.bump(); } // do some more stuff It gets annoying to type that out each time, so we could define a eat_whitespace method:
// Only hypothetical; don’t write this! impl Parser { pub(crate) fn eat_whitespace(&amp;amp;mut self) { if p.peek() == Some(SyntaxKind::Whitespace) { p.bump(); } } } Nevertheless, being forced to write out a p.</description></item><item><title>Part Twelve: Terminology</title><link>https://arzg.github.io/lang/12/</link><pubDate>
Fri, 04 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/12/</guid><description>
Way back when I posted Part Three on Reddit, u/moon-chilled informed me that the terminology of ‘bindings’ that I had introduced in that part was incorrect. I planned to address this in the next part, but forgot about it. Recently I remembered it for some reason, so I thought it might be a good idea to change now when very little code is affected.
Here’s u/moon-chilled’s comment in full:
A variable that you can’t vary doesn’t make much sense</description></item><item><title>Part Eleven: Refinements</title><link>https://arzg.github.io/lang/11/</link><pubDate>
Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/11/</guid><description>
We’ve got a number of topics to cover this time, so let’s get started.
A bug fix u/mozjag pointed out on Reddit that the regex we’re using to lex identifiers mandates that they have a length of two, when we could also allow identifiers with a single character. Let’s write a test for lexing a single-letter identifier to verify the bug is actually present:
// lexer.rs #[cfg(test)] mod tests { // snip #[test] fn lex_single_char_identifier() { check(&amp;quot;x&amp;quot;, SyntaxKind::Ident); } // snip } $ cargo t -q running 21 tests .</description></item><item><title>Part Ten: Starting Again</title><link>https://arzg.github.io/lang/10/</link><pubDate>
Sun, 15 Nov 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/10/</guid><description>
In Part Nine I described the reasons for switching to Rowan and a lexer over the current lexerless parsing system we’ve developed in crate::utils. Read that before reading on here.
Wiping the project Sadly, the moment has arrived. It’s time to delete what we’ve created, since almost none of it will be reusable.
$ rm -r crates/{eldiro,eldiro-cli}/src Let’s add in placeholder files so everything still compiles:
// crates/eldiro/src/lib.rs #[cfg(test)] mod tests { #[test] fn it_works() { assert_eq!</description></item><item><title>Part Nine: Function Calls</title><link>https://arzg.github.io/lang/9/</link><pubDate>
Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/9/</guid><description>
As we did last time, we need to choose a syntax, this time for function calls.
// Rust syntax f(a, b, c); no_params(); Again, as I said in the previous part, parentheses and commas are annoying. Hence, Eldiro will use a different syntax in the spirit of ML-family languages:
f a b c no_params Much cleaner! This doesn’t syntactically distinguish between calling a function with no parameters and using a binding, though &amp;ndash; we don’t know during parsing whether no_params is a binding usage, or a function call with no parameters.</description></item><item><title>Part Eight: Function Definitions</title><link>https://arzg.github.io/lang/8/</link><pubDate>
Thu, 08 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/8/</guid><description>
First, we need to decide on a syntax. Let’s start with Rust’s syntax:
fn frobnicate(foo: String, bar: String) -&amp;gt; Vec&amp;lt;Bar&amp;gt; { ... } Eldiro doesn’t have types (yet), so we need to remove those:1
fn frobnicate(foo, bar) { ... } Parentheses and commas are annoying, so let’s get rid of those:
fn frobnicate foo bar { ... } Often we have functions whose body is just a single statement.</description></item><item><title>Part Seven: A REPL</title><link>https://arzg.github.io/lang/7/</link><pubDate>
Wed, 07 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/7/</guid><description>
In case you aren’t familiar with the concept, a read-eval-print-loop, or REPL, is a program that lets you interactively use a programming language. Here’s a hypothetical session with an Eldiro REPL:
$ eldiro → 5 5 → 10 - 7 3 → let one = 1 → one 1 To implement such a thing, the REPL needs to have access to Stmt::new, Val and Env (to store the evaluation environment between inputs).</description></item><item><title>Part Six: Blocks</title><link>https://arzg.github.io/lang/6/</link><pubDate>
Tue, 06 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/6/</guid><description>
By the end of this post, Eldiro will have blocks. By block, I mean the Rust meaning, not one from any other programming language.1
What is a block, anyway? In Rust (and Eldiro, once they are implemented), blocks are a way to group a bunch of bindings together and ensure that they are not accessible from outside the block. For example, foo and bar aren’t accessible outside the curly braces.</description></item><item><title>Part Five: Binding Usages</title><link>https://arzg.github.io/lang/5/</link><pubDate>
Mon, 05 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/5/</guid><description>
After Part Four, the longest so far, this will be a relatively short post: we’ll be adding support for binding usages. Here’s the syntax we’re after:
let a = 10 let b = a where a is a binding usage.
Parsing Let’s begin with the parser. Add pub mod binding_usage; to lib.rs, and create a new file at src/binding_usage.rs. As usual, we’ll start with a test:
#[cfg(test)] mod tests { use super::*; #[test] fn parse_binding_usage() { assert_eq!</description></item><item><title>Part Four: Backtracking</title><link>https://arzg.github.io/lang/4/</link><pubDate>
Mon, 05 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/4/</guid><description>
In this part of the series we’ll start with the goal of allowing Exprs to be numbers. In case you’ve forgotten, at the moment Exprs have to be mathematical operations, making simple things like let x = 5 impossible.
Let’s start by hopping over to Expr’s definition in expr.rs, and changing it to be an enum that can hold either a mathematical operation, or a number:
#[derive(Debug, PartialEq)] pub enum Expr { Number(Number), Operation { lhs: Number, rhs: Number, op: Op }, } We’ve got errors appearing all over the place; let’s fix parsing first.</description></item><item><title>Part Three: Defining Variables</title><link>https://arzg.github.io/lang/3/</link><pubDate>
Wed, 09 Sep 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/3/</guid><description>
Welcome back! This time, we’ll parse and evaluate variable definitions.
Parsing Before we can begin writing a parser, we need to decide on a syntax. Since we like Rust, we’ll go for a similar syntax:
let a = 5 To start off, Eldiro will only include immutable variables, or bindings,1 as they’re sometimes called (at least that’s what I’ll be calling them for the rest of this series).
Although we’d usually start writing a test here, I fear that lib.</description></item><item><title>Part Two: Whitespace Support</title><link>https://arzg.github.io/lang/2/</link><pubDate>
Wed, 09 Sep 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/2/</guid><description>
Last time, we made a parser for simple unnested mathematical expressions, such as 1+1 or 3*4. In this post, we’ll add support for whitespace (so that users of Eldiro will be able to use 2 + 2 instead of 2+2).
We can achieve this by creating an extract_whitespace function similar to extract_digits:
// utils.rs // Let’s copy-paste from extract_digits pub(crate) fn extract_whitespace(s: &amp;amp;str) -&amp;gt; (&amp;amp;str, &amp;amp;str) { let whitespace_end = s .</description></item><item><title>Part One: A Basic Parser</title><link>https://arzg.github.io/lang/1/</link><pubDate>
Tue, 08 Sep 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/1/</guid><description>
The most fundamental part of any language is the parser1 &amp;ndash; a piece of software whose purpose is to take a flat structure (usually text in some form) and convert it into a tree structure. In this post, we’ll make a parser for mathematical expressions that don’t contain nesting. For example, 1 + 1 is allowed, but 2 * 3 + 4 isn’t (because that’s shorthand for (2 * 3) + 4, and thus contains nesting).</description></item><item><title>Part Zero: Getting set up</title><link>https://arzg.github.io/lang/0/</link><pubDate>
Mon, 07 Sep 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/0/</guid><description>
Let’s create a new Rust project:
$ cargo new --lib error: The following required arguments were not provided: &amp;lt;path&amp;gt; USAGE: cargo new &amp;lt;path&amp;gt; --lib For more information try --help Oh, yeah, we need a name. Hmmm. Let’s open the thesaurus and search for ‘language’:
Speech, writing, conversation … ooh, utterance. I like the sound of that! Time to check if it’s taken.
Damn, it’s already taken. Maybe I can do what so many projects seem to do and use a random non-English word.</description></item></channel></rss>