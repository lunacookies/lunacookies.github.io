<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Part Sixteen: Refactoring · arzg’s website</title><link rel=stylesheet href=https://arzg.github.io/scss/main.04c23afe51262a10ee61829da41f4d7318ff311ed0d0bcbf1db0fde96e3830f4.css integrity="sha256-BMI6/lEmKhDuYYKdpB9Ncxj/MR7Q0Ly/HbD96W44MPQ="><script src=https://unpkg.com/quicklink@2.0.0/dist/quicklink.umd.js></script>
<script src=https://unpkg.com/anchor-js@4.3.1/anchor.min.js></script>
<script src=https://unpkg.com/prismjs@1.25.0/components/prism-core.min.js></script>
<script src=https://unpkg.com/prismjs@1.25.0/plugins/autoloader/prism-autoloader.min.js></script>
<script>window.onload=()=>{quicklink.listen()},document.addEventListener("DOMContentLoaded",function(a){anchors.add("main h1")})</script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest></head><body><nav class=site-navigation><ul><li><a href=/>Home</a></li><li><a href=/blog/>Blog</a></li><li class=current><a href=/lang/>Make A Language</a></li></ul></nav><header class=header-area><h1 class=title>Part Sixteen: Refactoring</h1><section class=page-info><ul><li>17 December 2020</li><li>976 words</li><li>five minute read</li></ul></section></header><main><h1 id=refactoring-expr_binding_power>Refactoring <code>expr_binding_power</code></h1><p>The right-hand side of the <code>let lhs = ...</code> in <code>expr_binding_power</code> is getting quite long, so let’s extract it to its own function:</p><pre><code class=language-rust>// expr.rs

use super::marker::CompletedMarker;
use super::Parser;
use crate::lexer::SyntaxKind;

// snip

fn expr_binding_power(p: &amp;mut Parser, minimum_binding_power: u8) {
    let mut lhs = if let Some(lhs) = lhs(p) {
        lhs
    } else {
        return; // we’ll handle errors later.
    };

    // snip
}

fn lhs(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    let cm = match p.peek() {
        Some(SyntaxKind::Number) =&gt; {
            // snip
        }
        // all the other arms are also here, unchanged
        _ =&gt; return None,
    };

    Some(cm)
}
</code></pre><pre><code class=language-->$ cargo t -q
running 35 tests
...................................
test result: ok. 35 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><p>Let’s also extract the parsers for each of the <code>match</code> arms in <code>lhs</code>:</p><pre><code class=language-rust>fn lhs(p: &amp;mut Parser) -&gt; Option&lt;CompletedMarker&gt; {
    let cm = match p.peek() {
        Some(SyntaxKind::Number) =&gt; literal(p),
        Some(SyntaxKind::Ident) =&gt; variable_ref(p),
        Some(SyntaxKind::Minus) =&gt; prefix_expr(p),
        Some(SyntaxKind::LParen) =&gt; paren_expr(p),
        _ =&gt; return None,
    };

    Some(cm)
}

// snip

fn literal(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert_eq!(p.peek(), Some(SyntaxKind::Number));

    let m = p.start();
    p.bump();
    m.complete(p, SyntaxKind::Literal)
}

fn variable_ref(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert_eq!(p.peek(), Some(SyntaxKind::Ident));

    let m = p.start();
    p.bump();
    m.complete(p, SyntaxKind::VariableRef)
}

fn prefix_expr(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert_eq!(p.peek(), Some(SyntaxKind::Minus));

    let m = p.start();

    let op = PrefixOp::Neg;
    let ((), right_binding_power) = op.binding_power();

    // Eat the operator’s token.
    p.bump();

    expr_binding_power(p, right_binding_power);

    m.complete(p, SyntaxKind::PrefixExpr)
}

fn paren_expr(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert_eq!(p.peek(), Some(SyntaxKind::LParen));

    let m = p.start();

    p.bump();
    expr_binding_power(p, 0);

    assert_eq!(p.peek(), Some(SyntaxKind::RParen));
    p.bump();

    m.complete(p, SyntaxKind::ParenExpr)
}
</code></pre><p>Writing out that <code>assert_eq!</code> at the start of each subparser is getting annoying. Let’s write a helper method on <code>Parser</code> to make this easier:</p><pre><code class=language-rust>// parser.rs

impl&lt;'l, 'input&gt; Parser&lt;'l, 'input&gt; {
    // snip

    fn at(&amp;mut self, kind: SyntaxKind) -&gt; bool {
        self.peek() == Some(kind)
    }

    // snip
}
</code></pre><p>We can now update all those <code>assert_eq!</code>s:</p><pre><code class=language-rust>// expr.rs

fn literal(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert!(p.at(SyntaxKind::Number));

    // snip
}

fn variable_ref(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert!(p.at(SyntaxKind::Ident));

    // snip
}

fn prefix_expr(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert!(p.at(SyntaxKind::Minus));

    // snip
}

fn paren_expr(p: &amp;mut Parser) -&gt; CompletedMarker {
    assert!(p.at(SyntaxKind::LParen));

    // snip

    assert!(p.at(SyntaxKind::RParen));
    p.bump();

    // snip
}
</code></pre><pre><code class=language-->$ cargo t -q
running 35 tests
...................................
test result: ok. 35 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><h1 id=lexeme-versus-token>‘Lexeme’ versus ‘token’</h1><p>I was under the impression that a ‘token’ is an identifier of a given chunk of the input (in our case a <code>SyntaxKind</code>), and that a ‘lexeme’ is a token plus the text that token applies to. Once again it seems that my assumptions about terminology are incorrect: although <a href=https://stackoverflow.com/a/14958865>this StackOverflow answer</a> agrees with my definition of ‘token’, it explains that the word ‘token’ can also be used to describe what I’ve been calling a ‘lexeme’. My definition of ‘lexeme’ is incorrect; the answer says that ‘lexeme’ refers to the text a token applies to, <em>and that only.</em></p><p>Use your editor’s project-wide search and replace to rename <code>Lexeme</code> to <code>Token</code>, <code>lexeme</code> to <code>token</code> and <code>'l</code> to <code>'t</code>. Make sure to run <code>cargo fmt</code> afterwards to maintain formatting.</p><p>See <a href=https://github.com/arzg/eldiro/commit/0d5ba1682698654c27c20139fc7f1ba139d70ad1>the commit</a> where this change is made if you have any trouble.</p><h1 id=removing-unneeded-fields-from-event>Removing unneeded fields from <code>Event</code></h1><p>When we want to add a token to the current branch, we use this event:</p><pre><code class=language-rust>Event::AddToken {
    kind: SyntaxKind::Foo,
    text: &quot;bar&quot;.into(),
}
</code></pre><p>We get the <code>SyntaxKind</code> and text of this token from the source, which stores an array of tokens internally. Once parsing is complete, the sink goes through each event and processes it. The sink also stores the same array of tokens.</p><p>This means that the the parser doesn’t need to tell the sink the <code>SyntaxKind</code> and text of each token it’s adding, since the sink already has the data to work this out. Let’s remove the unnecessary fields from <code>Event::AddToken</code>:</p><pre><code class=language-rust>// event.rs

use crate::lexer::SyntaxKind;

#[derive(Debug, Clone, PartialEq)]
pub(super) enum Event {
    StartNode {
        kind: SyntaxKind,
        forward_parent: Option&lt;usize&gt;,
    },
    AddToken,
    FinishNode,
    Placeholder,
}
</code></pre><p>This has reduced the size of <code>Event</code> from 32 bytes to 24 bytes. Let’s update <code>Parser::bump</code> to match:</p><pre><code class=language-rust>// parser.rs

impl&lt;'t, 'input&gt; Parser&lt;'t, 'input&gt; {
    // snip

    fn bump(&amp;mut self) {
        self.source.next_token().unwrap();
        self.events.push(Event::AddToken);
    }

    // snip
}
</code></pre><p>We also need to change <code>Sink</code>:</p><pre><code class=language-rust>// sink.rs

use super::event::Event;
use crate::lexer::Token;
use crate::syntax::EldiroLanguage;
use rowan::{GreenNode, GreenNodeBuilder, Language};
use std::mem;

// snip

impl&lt;'t, 'input&gt; Sink&lt;'t, 'input&gt; {
    // snip

    pub(super) fn finish(mut self) -&gt; GreenNode {
        for idx in 0..self.events.len() {
            match mem::replace(&amp;mut self.events[idx], Event::Placeholder) {
                // snip
                Event::AddToken =&gt; self.token(),
                // snip
            }

            self.eat_trivia();
        }

        self.builder.finish()
    }

    fn eat_trivia(&amp;mut self) {
        while let Some(token) = self.tokens.get(self.cursor) {
            if !token.kind.is_trivia() {
                break;
            }

            self.token();
        }
    }

    fn token(&amp;mut self) {
        let Token { kind, text } = self.tokens[self.cursor];

        self.builder
            .token(EldiroLanguage::kind_to_raw(kind), text.into());

        self.cursor += 1;
    }
}
</code></pre><pre><code class=language-->$ cargo t -q
running 35 tests
...................................
test result: ok. 35 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre><h1 id=binaryinfix-and-unaryprefix>Binary/infix and unary/prefix</h1><p>I’ve used these terms inconsistently throughout the series, and thought it might be a good time to clean this up.</p><ul><li><em>Binary operator</em> means ‘an operator with two operands’</li><li><em>Infix operator</em> means ‘an operator placed between its operands’</li><li><em>Unary operator</em> means ‘an operator with one operand’</li><li><em>Prefix operator</em> means ‘an operator placed before its operands’</li></ul><p>I’ve used the ‘binary’ terminology in <code>SyntaxKind</code>, but used ‘infix’ for the type representing these binary operators in <code>expr.rs</code>. I’ve used the ‘prefix’ terminology in both <code>SyntaxKind</code> and <code>expr.rs</code>.</p><p>To stay consistent we should name things after the position of the operator, or the number of operands. The parser has to worry about the position, but future parts of Eldiro (such as an interpreter) have to worry about the number of operands. To convey this we’ll rename <code>SyntaxKind::BinaryExpr</code> to <code>SyntaxKind::InfixExpr</code>, <code>InfixOp</code> to <code>BinaryOp</code> and <code>PrefixOp</code> to <code>UnaryOp</code>. Make sure you change the tests too! If you get stuck feel free to look at <a href=https://github.com/arzg/eldiro/commit/1d494614433548cf045dcb5abbf91a8b937c6832>the relevant commit</a>.</p></main><nav class=page-navigation><div class=prev><p class=hint>Previously</p><a href=https://arzg.github.io/lang/15/>Part Fifteen: Markers</a></div><div class=next><p class=hint>Next up</p><a href=https://arzg.github.io/lang/17/>Part Seventeen: Crates</a></div><div style=clear:both></div></nav></body></html>