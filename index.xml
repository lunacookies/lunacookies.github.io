&lt;?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>
Home on
arzg’s website</title><link>https://arzg.github.io/</link><description>
Recent content
in Home
on arzg’s website</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><atom:link href="https://arzg.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Part Nineteen: Code Representations</title><link>https://arzg.github.io/lang/19/</link><pubDate>
Fri, 24 Jan 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/19/</guid><description>
So far we have only used two different data structures to represent code:
abstract syntax trees concrete syntax trees An abstract syntax tree is a data structure that represents the bare minimum about a chunk of code. We used ASTs in the early parts of this series prior to the Rowan rewrite. For example, here’s an AST that represents variable definitions:
struct VariableDef{name: String,value: Expr,}enum Expr{// snip }Note how it doesn’t include the let token or the =, and ignores trivia like whitespace and comments; it’s abstract, and only contains the information necessary to implement, say, a compiler.</description></item><item><title>Part Eighteen: Errors</title><link>https://arzg.github.io/lang/18/</link><pubDate>
Mon, 21 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/18/</guid><description>
So far, our parser has only concerned itself with input that is correct. In a world of IDEs and language servers, however, the input to our parser will be wrong more often than not. Therefore, it is important that our parser can:
recover gracefully from errors infer as detailed a syntax tree from the input as possible report errors in a user-friendly manner Unfortunately for us, the only thing our parser currently supports is arithmetic expressions, which don’t make error recovery techniques easy to demonstrate.</description></item><item><title>Part Seventeen: Crates</title><link>https://arzg.github.io/lang/17/</link><pubDate>
Fri, 18 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/17/</guid><description>
I’m not a fan of how, currently, all the submodules of crate::parser can access the internals of our parser. This access makes sense for marker.rs, but not for, say, expr.rs. These other modules should have to go through the parser’s API. We can enforce these sorts of visibility issues by breaking our project up into crates.
Extracting the lexer The first part of Eldiro we’ll create a separate crate for is the lexer.</description></item><item><title>Part Sixteen: Refactoring</title><link>https://arzg.github.io/lang/16/</link><pubDate>
Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/16/</guid><description>
Refactoring expr_binding_power The right-hand side of the let lhs = ... in expr_binding_power is getting quite long, so let’s extract it to its own function:
// expr.rs usesuper::marker::CompletedMarker;usesuper::Parser;usecrate::lexer::SyntaxKind;// snip fn expr_binding_power(p: &amp;amp;mutParser,minimum_binding_power: u8){letmutlhs=ifletSome(lhs)=lhs(p){lhs}else{return;// we’ll handle errors later. };// snip }fn lhs(p: &amp;amp;mutParser)-&amp;gt; Option&amp;lt;CompletedMarker&amp;gt;{letcm=matchp.peek(){Some(SyntaxKind::Number)=&amp;gt;{// snip }// all the other arms are also here, unchanged _=&amp;gt;returnNone,};Some(cm)}$ cargo t -q running 35 tests ................................... test result: ok. 35 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out Let’s also extract the parsers for each of the match arms in lhs:</description></item><item><title>Part Fifteen: Markers</title><link>https://arzg.github.io/lang/15/</link><pubDate>
Wed, 16 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/15/</guid><description>
A ‘marker’ is an abstraction over Rowan that makes working with it nicer, and also allows for some fancier parsing techniques. You can think of them as a fancy version of the checkpoints we’ve been using up to this point. Here’s a rough sketch of the API we’ll create:
implParser{fn start(&amp;amp;mutself)-&amp;gt; Marker;}struct Marker{...}implMarker{fn complete(self,p: &amp;amp;mutParser,kind: SyntaxKind)-&amp;gt; CompletedMarker;}struct CompletedMarker{...}implCompletedMarker{fn precede(self,p: &amp;amp;mutParser)-&amp;gt; Marker;}Additionally, we will ensure that Marker panics if it has been dropped without being completed.</description></item><item><title>Part Fourteen: Comments</title><link>https://arzg.github.io/lang/14/</link><pubDate>
Thu, 10 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/14/</guid><description>
The first thing we need to do is teach the lexer to recognise comments. We’ll begin with a test:
// lexer.rs #[cfg(test)]mod tests{// snip #[test]fn lex_comment(){check(&amp;#34;# foo&amp;#34;,SyntaxKind::Comment);}}Here’s the implementation:
pub(crate)enum SyntaxKind{// snip #[regex(&amp;#34;#.*&amp;#34;)]Comment,#[error]Error,Root,BinaryExpr,PrefixExpr,}Take note of how we aren’t using #[logos::skip] here; instead, we are explicitly including comments in the output of our lexer. We do this to ensure that the parser fully contains the input text, which makes the parser lossless.</description></item><item><title>Part Thirteen: Whitespace &amp; Events</title><link>https://arzg.github.io/lang/13/</link><pubDate>
Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/13/</guid><description>
The simple but annoying approach We could check for the presence of whitespace after every token:
// do some stuff ifp.peek()==Some(SyntaxKind::Whitespace){p.bump();}// do some more stuff It gets annoying to type that out each time, so we could define a eat_whitespace method:
// Only hypothetical; don’t write this! implParser{pub(crate)fn eat_whitespace(&amp;amp;mutself){ifp.peek()==Some(SyntaxKind::Whitespace){p.bump();}}}Nevertheless, being forced to write out a p.eat_whitespace() call every single time we add a token to a branch is annoying.
The complex but invisible approach Instead of manually handling whitespace, we can create our own abstraction over Rowan in the form of events &amp;ndash; every time Parser::start_node is called, for example, we’ll push to a Vec of Event enums.</description></item><item><title>Part Twelve: Terminology</title><link>https://arzg.github.io/lang/12/</link><pubDate>
Fri, 04 Dec 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/12/</guid><description>
Way back when I posted Part Three on Reddit, u/moon-chilled informed me that the terminology of ‘bindings’ that I had introduced in that part was incorrect. I planned to address this in the next part, but forgot about it. Recently I remembered it for some reason, so I thought it might be a good idea to change now when very little code is affected.
Here’s u/moon-chilled’s comment in full:
A variable that you can’t vary doesn’t make much sense</description></item><item><title>Part Eleven: Refinements</title><link>https://arzg.github.io/lang/11/</link><pubDate>
Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/11/</guid><description>
We’ve got a number of topics to cover this time, so let’s get started.
A bug fix u/mozjag pointed out on Reddit that the regex we’re using to lex identifiers mandates that they have a length of two, when we could also allow identifiers with a single character. Let’s write a test for lexing a single-letter identifier to verify the bug is actually present:
// lexer.rs #[cfg(test)]mod tests{// snip #[test]fn lex_single_char_identifier(){check(&amp;#34;x&amp;#34;,SyntaxKind::Ident);}// snip }$ cargo t -q running 21 tests .</description></item><item><title>Part Ten: Starting Again</title><link>https://arzg.github.io/lang/10/</link><pubDate>
Sun, 15 Nov 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/10/</guid><description>
In Part Nine I described the reasons for switching to Rowan and a lexer over the current lexerless parsing system we’ve developed in crate::utils. Read that before reading on here.
Wiping the project Sadly, the moment has arrived. It’s time to delete what we’ve created, since almost none of it will be reusable.
$ rm -r crates/{eldiro,eldiro-cli}/src Let’s add in placeholder files so everything still compiles:
// crates/eldiro/src/lib.rs #[cfg(test)]mod tests{#[test]fn it_works(){assert_eq!</description></item><item><title>Part Nine: Function Calls</title><link>https://arzg.github.io/lang/9/</link><pubDate>
Sun, 08 Nov 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/9/</guid><description>
As we did last time, we need to choose a syntax, this time for function calls.
// Rust syntax f(a,b,c);no_params();Again, as I said in the previous part, parentheses and commas are annoying. Hence, Eldiro will use a different syntax in the spirit of ML-family languages:
f a b c no_params Much cleaner! This doesn’t syntactically distinguish between calling a function with no parameters and using a binding, though &amp;ndash; we don’t know during parsing whether no_params is a binding usage, or a function call with no parameters.</description></item><item><title>Part Eight: Function Definitions</title><link>https://arzg.github.io/lang/8/</link><pubDate>
Thu, 08 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/8/</guid><description>
First, we need to decide on a syntax. Let’s start with Rust’s syntax:
fn frobnicate(foo: String,bar: String)-&amp;gt; Vec&amp;lt;Bar&amp;gt;{...}Eldiro doesn’t have types (yet), so we need to remove those:1
fn frobnicate(foo, bar) { ... } Parentheses and commas are annoying, so let’s get rid of those:
fn frobnicate foo bar { ... } Often we have functions whose body is just a single statement. Here’s a contrived example:
fn add x y { x + y } It can be convenient to not force function bodies to be blocks in these cases.</description></item><item><title>Part Seven: A REPL</title><link>https://arzg.github.io/lang/7/</link><pubDate>
Wed, 07 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/7/</guid><description>
In case you aren’t familiar with the concept, a read-eval-print-loop, or REPL, is a program that lets you interactively use a programming language. Here’s a hypothetical session with an Eldiro REPL:
$ eldiro → 5 5 → 10 - 7 3 → let one = 1 → one 1 To implement such a thing, the REPL needs to have access to Stmt::new, Val and Env (to store the evaluation environment between inputs).</description></item><item><title>Part Six: Blocks</title><link>https://arzg.github.io/lang/6/</link><pubDate>
Tue, 06 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/6/</guid><description>
By the end of this post, Eldiro will have blocks. By block, I mean the Rust meaning, not one from any other programming language.1
What is a block, anyway? In Rust (and Eldiro, once they are implemented), blocks are a way to group a bunch of bindings together and ensure that they are not accessible from outside the block. For example, foo and bar aren’t accessible outside the curly braces.</description></item><item><title>Part Five: Binding Usages</title><link>https://arzg.github.io/lang/5/</link><pubDate>
Mon, 05 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/5/</guid><description>
After Part Four, the longest so far, this will be a relatively short post: we’ll be adding support for binding usages. Here’s the syntax we’re after:
let a = 10 let b = a where a is a binding usage.
Parsing Let’s begin with the parser. Add pub mod binding_usage; to lib.rs, and create a new file at src/binding_usage.rs. As usual, we’ll start with a test:
#[cfg(test)]mod tests{usesuper::*;#[test]fn parse_binding_usage(){assert_eq!(BindingUsage::new(&amp;#34;abc&amp;#34;),Ok((&amp;#34;&amp;#34;,BindingUsage{name: &amp;#34;abc&amp;#34;.to_string(),},)),);}}Let’s add the definition of BindingUsage:</description></item><item><title>Part Four: Backtracking</title><link>https://arzg.github.io/lang/4/</link><pubDate>
Mon, 05 Oct 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/4/</guid><description>
In this part of the series we’ll start with the goal of allowing Exprs to be numbers. In case you’ve forgotten, at the moment Exprs have to be mathematical operations, making simple things like let x = 5 impossible.
Let’s start by hopping over to Expr’s definition in expr.rs, and changing it to be an enum that can hold either a mathematical operation, or a number:
#[derive(Debug, PartialEq)]pubenum Expr{Number(Number),Operation{lhs: Number,rhs: Number,op: Op},}We’ve got errors appearing all over the place; let’s fix parsing first.</description></item><item><title>Part Three: Defining Variables</title><link>https://arzg.github.io/lang/3/</link><pubDate>
Wed, 09 Sep 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/3/</guid><description>
Welcome back! This time, we’ll parse and evaluate variable definitions.
Parsing Before we can begin writing a parser, we need to decide on a syntax. Since we like Rust, we’ll go for a similar syntax:
leta=5To start off, Eldiro will only include immutable variables, or bindings,1 as they’re sometimes called (at least that’s what I’ll be calling them for the rest of this series).
Although we’d usually start writing a test here, I fear that lib.</description></item><item><title>Part Two: Whitespace Support</title><link>https://arzg.github.io/lang/2/</link><pubDate>
Wed, 09 Sep 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/2/</guid><description>
Last time, we made a parser for simple unnested mathematical expressions, such as 1+1 or 3*4. In this post, we’ll add support for whitespace (so that users of Eldiro will be able to use 2 + 2 instead of 2+2).
We can achieve this by creating an extract_whitespace function similar to extract_digits:
// utils.rs // Let’s copy-paste from extract_digits pub(crate)fn extract_whitespace(s: &amp;amp;str)-&amp;gt; (&amp;amp;str,&amp;amp;str){letwhitespace_end=s.char_indices().find_map(|(idx,c)|ifc==&amp;#39; &amp;#39;{None}else{Some(idx)}).unwrap_or_else(||s.len());letwhitespace=&amp;amp;s[..whitespace_end];letremainder=&amp;amp;s[whitespace_end..];(remainder,whitespace)}#[cfg(test)]mod tests{// snip #[test]fn extract_spaces(){assert_eq!(extract_whitespace(&amp;#34; 1&amp;#34;),(&amp;#34;1&amp;#34;,&amp;#34; &amp;#34;));}}Although this does indeed work, it involves quite a bit of repetition.</description></item><item><title>Part One: A Basic Parser</title><link>https://arzg.github.io/lang/1/</link><pubDate>
Tue, 08 Sep 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/1/</guid><description>
The most fundamental part of any language is the parser1 &amp;ndash; a piece of software whose purpose is to take a flat structure (usually text in some form) and convert it into a tree structure. In this post, we’ll make a parser for mathematical expressions that don’t contain nesting. For example, 1 + 1 is allowed, but 2 * 3 + 4 isn’t (because that’s shorthand for (2 * 3) + 4, and thus contains nesting).</description></item><item><title>Part Zero: Getting set up</title><link>https://arzg.github.io/lang/0/</link><pubDate>
Mon, 07 Sep 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/lang/0/</guid><description>
Let’s create a new Rust project:
$ cargo new --lib error: The following required arguments were not provided: &amp;lt;path&amp;gt; USAGE: cargo new &amp;lt;path&amp;gt; --lib For more information try --help Oh, yeah, we need a name. Hmmm. Let’s open the thesaurus and search for ‘language’:
Speech, writing, conversation … ooh, utterance. I like the sound of that! Time to check if it’s taken.
Damn, it’s already taken. Maybe I can do what so many projects seem to do and use a random non-English word.</description></item><item><title>A Post-Mortem of syntax-rust</title><link>https://arzg.github.io/blog/post-mortem/</link><pubDate>
Wed, 22 Jul 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/blog/post-mortem/</guid><description>
Earlier this year, I began a project that aims to create a development environment that is orthogonal, fast, and pleasant to use. It would be difficult for one person to write this all by themselves; my aim was to create but a few of the components involved in such a project. My focus started with the shell, which I called Fjord. Then, my focus shifted to creating a text editor.</description></item><item><title>A New Direction for Fjord</title><link>https://arzg.github.io/blog/new-direction/</link><pubDate>
Sat, 30 May 2020 00:00:00 +0000</pubDate><guid>https://arzg.github.io/blog/new-direction/</guid><description>
Some context Fjord is a project I’m working on. It started off as a ‘shell’ that has all the applications you want to run from it baked into the shell itself; essentially, a scripting language with the ability to call Rust functions. The plan was for Fjord to be used primarily as a shell &amp;ndash; that is, a shell that cannot run programs, only call functions. Stupid, I know.
Why Fjord is the way it is I’ve always been interested in Plan 9 and its philosophy &amp;ndash; Unix turned up to eleven, as they say.</description></item></channel></rss>